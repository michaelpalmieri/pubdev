
Here’s a detailed vSAN OSA deployment plan using three ESXi hosts, each with two 10GbE NICs. The plan outlines every step needed to design, configure, and deploy the vSAN cluster using Original Storage Architecture (OSA).

📦 vSAN OSA Deployment Plan (3 Hosts, 2x10GbE per Host)
🧱 1. Infrastructure Overview
Cluster Size: 3 ESXi Hosts

vSAN Architecture: Original Storage Architecture (OSA)

Network: Each host has 2 x 10GbE NICs

Disks per Host:

1 x SSD (for cache)

2–7 x HDDs (for capacity)

⚙️ 2. Preparation and Prerequisites
Component	Description
Hardware	VMware HCL-compliant servers with two 10GbE NICs
Software	VMware vSphere (ESXi 7.0 or later), vCenter Server
Licensing	VMware vSAN license (Standard, Advanced, or Enterprise)
Disks	SSD for cache, HDD or SSD for capacity (min. 1 cache + 1 capacity disk per host)
Time sync	NTP configured on all hosts and vCenter
Firmware/Drivers	Updated firmware for SSDs, NICs, HBA; drivers as per HCL

🌐 3. Network Configuration (2 x 10GbE NICs)
A. Logical Design
Traffic Type	VMkernel	VLAN	Active/Standby NICs
Management	vmk0	VLAN 10	vmnic0 Active / vmnic1 Standby
vMotion	vmk1	VLAN 20	vmnic1 Active / vmnic0 Standby
vSAN	vmk2	VLAN 30	vmnic0 Active / vmnic1 Standby

B. vSwitch Design
Use vSphere Distributed Switch (vDS) (recommended) or vSwitch Standard (vSS).

Enable Jumbo Frames (MTU 9000) for performance.

Create separate port groups for vMotion and vSAN.

🛠️ 4. Deployment Steps
🔹 Step 1: Install and Configure ESXi on Each Host
Install ESXi 7.0+ on all three hosts.

Configure Management Network (vmk0).

Set hostname, IP, NTP, DNS.

🔹 Step 2: Create vDS and Configure VMkernel Adapters
In vCenter, create a vSphere Distributed Switch (vDS).

Add both 10GbE NICs to the vDS uplinks.

Create 3 Port Groups:

PG-Management (VLAN 10)

PG-vMotion (VLAN 20)

PG-vSAN (VLAN 30)

Add VMkernel adapters:

vmk0: Management (attach to PG-Management)

vmk1: vMotion (attach to PG-vMotion)

vmk2: vSAN (attach to PG-vSAN)

Ensure each VMkernel has a static IP address.

🔹 Step 3: Configure NIC Teaming and MTU
On all port groups, configure:

Failover Order for vmk1 and vmk2 (see table above).

MTU 9000 on physical switches, vDS, and VMkernel ports.

Run jumbo frame test:

bash
Copy
Edit
vmkping -I vmk2 -d -s 8972 <peer vmk2 IP>
🔹 Step 4: Add Hosts to vCenter
Connect all three ESXi hosts to vCenter Server.

Place them in a new cluster called vSAN-Cluster.

🔹 Step 5: Enable vSAN on the Cluster
Right-click the cluster → vSAN → Enable.

Choose:

vSAN Original Storage Architecture (OSA)

Manual Disk Claiming

Confirm vmk2 is selected for vSAN traffic.

🔹 Step 6: Claim Disks and Create Disk Groups
On each host:

Create 1 or more Disk Groups:

1 x SSD (cache tier)

1–7 x HDDs (capacity tier)

Example:

yaml
Copy
Edit
Disk Group 1:
  - Cache: 400 GB SSD
  - Capacity: 2 x 2 TB HDDs
🔹 Step 7: Validate and Test Cluster Health
Open vSAN > Monitor > Skyline Health.

Ensure:

All hosts are contributing storage.

Disk groups are healthy.

Network communication works (use vmkping if needed).

📦 5. Storage Policy Configuration
Create VM Storage Policies to define availability and performance:

Policy Name	FTT	RAID Type	Min. Hosts	Use Case
FTT1-Mirror	1	RAID-1 (Mirroring)	3	High availability
FTT0	0	None	1	Non-critical VMs / testing

Apply appropriate policy when provisioning or migrating VMs.

🛡️ 6. High Availability and vMotion
Enable vSphere HA for automatic VM failover.

Enable vMotion to allow live migration.

Test vMotion between hosts to confirm correct network configuration.

📈 7. Monitoring and Maintenance
Enable vSAN Performance Service.

Monitor via:

vSAN Skyline Health

vCenter Alarms

Optional: vRealize Operations (vROps)

For maintenance:

Put host in vSAN Maintenance Mode → “Ensure accessibility” (or "Full data migration" if removing a host).

Avoid simultaneous maintenance on multiple hosts.

✅ 8. Validation Checklist
Item	Status
All hosts added to vCenter	✅
vSAN enabled and disk groups created	✅
VMkernel ports for vSAN and vMotion configured	✅
Jumbo frames tested and verified	✅
Health checks pass	✅
Storage policies created and tested	✅






